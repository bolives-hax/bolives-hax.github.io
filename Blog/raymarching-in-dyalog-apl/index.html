<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta name=description><meta content="width=device-width,initial-scale=1" name=viewport><meta content=#ff7800 name=theme-color><link href=https://bolives-hax.github.io/Blog/raymarching-in-dyalog-apl/ rel=canonical><title>Raymarching meets dyalog APL - </title><link href=https://bolives-hax.github.io/style.css rel=stylesheet><link media="(prefers-color-scheme: dark)" href=https://bolives-hax.github.io/syntax-theme-dark.css rel=stylesheet><link media="(prefers-color-scheme: light)" href=https://bolives-hax.github.io/syntax-theme-light.css rel=stylesheet><style>:root {--primary-color-alpha:rgba(255,120,0,.2);--primary-color:#ff7800}</style><script src=https://bolives-hax.github.io/copy-button.js></script><link href=https://bolives-hax.github.io/favicon.png rel=icon type=image/png><link href=https://bolives-hax.github.io/apple-touch-icon.png rel=apple-touch-icon sizes=180x180 type=image/png><meta property=og:site_name><meta content="Raymarching meets dyalog APL - " property=og:title><meta content=https://bolives-hax.github.io/Blog/raymarching-in-dyalog-apl/ property=og:url><meta content="Writing a raymarcher in dyalog APL with no particular reason in mind :)" property=og:description><meta content=https://bolives-hax.github.io/card.png property=og:image><meta content=summary_large_image property=twitter:card><body><header id=site-nav><nav><a href=#main id=main-content tabindex=0>Skip to main content</a><ul><li id=home><a href=https://bolives-hax.github.io></a><li><a href=https://bolives-hax.github.io/Blog/>Blog</a><li id=feed><a href=https://bolives-hax.github.io/atom.xml> <svg viewbox="0 0 16 16" fill=currentColor height=16 width=16 xmlns=http://www.w3.org/2000/svg><path d="M1.988 1.988V3c.008.547.453.984 1 .988.004-.004.008-.004.012-.004v.028A8.977 8.977 0 0 1 11.988 13a.991.991 0 0 0 1 .984h1V13h-.004c0-.004 0-.004.004-.008C13.984 7.02 9.184 2.148 3.242 2.02A1.004 1.004 0 0 0 3 1.988v-.004zm0 4V7c.008.547.453.984 1 .988.004-.004.008-.004.012-.004V8a4.985 4.985 0 0 1 4.996 4.844 1.002 1.002 0 0 0 .988 1.145c.008-.005.012-.005.016-.005v.004h.984V13H10c0-3.793-3.047-6.898-6.82-6.992 0-.004-.004-.004-.004-.004A.892.892 0 0 0 3 5.988v-.004zm2 4a1.999 1.999 0 1 0-.002 3.998 1.999 1.999 0 0 0 .002-3.998m0 0"></path></svg> <span>Feed</span> </a></ul></nav></header><div class=container id=main><h1>Raymarching meets dyalog APL</h1><small> <time datetime=" 2024-04-28T00:00:00+00:00" pubdate>28 April 2024</time> <span>•</span> <span>Author: bl0v3</span> <span>•</span> <ul class=tags><li><a class=tag href=https://bolives-hax.github.io/tags/apl/>APL</a><li><a class=tag href=https://bolives-hax.github.io/tags/demo/>demo</a><li><a class=tag href=https://bolives-hax.github.io/tags/raymarching/>raymarching</a><li><a class=tag href=https://bolives-hax.github.io/tags/3d-graphics/>3D Graphics</a></ul> </small><div class="statement-container trigger"><strong class=big> <svg viewbox="0 0 16 16" fill=currentColor height=16 width=16 xmlns=http://www.w3.org/2000/svg><path d="M7.906.094C7.38.066 6.867.375 6.47 1.063L.219 12.656C-.316 13.621.266 15 1.313 15h13.156c.98 0 1.902-1.16 1.219-2.344L9.375 1.125C8.977.48 8.434.121 7.906.094M9 4v5c.008.527-.473 1-1 1s-1.008-.473-1-1V4zm-1 7c.55 0 1 .45 1 1s-.45 1-1 1-1-.45-1-1 .45-1 1-1m0 0"/></svg> Trigger Warning </strong><p>APL IS NOT MEANT TO BE USED FOR SUCH TASKS!!! It simply is not the language one should choose to perform such a task. With that being said. Keep in mind that as this was just a hobby weekend project there are various flaws and shortcomings to watch out for<ul><li>Performance isn’t too good as until I fixed some things multi-threading isn’t supported yet<li>Ray tracing / Ray marching is inherently slow thus such algorithms rarely used for real-time graphics but rather, for pretty much all CGI you’d see in your average movie made in the more recent years<li>There may be some flaws as I haven’t gotten the chance to take thaaaaat good of a look at APL specifically dyalog APL yet<li>This project essentially served to gain a better understanding of the language after all</ul></div><div class="statement-container disclaimer"><strong class=big> <svg viewbox="0 0 16 16" fill=currentColor height=16 width=16 xmlns=http://www.w3.org/2000/svg><path d="M7.906.094C7.38.066 6.867.375 6.47 1.063L.219 12.656C-.316 13.621.266 15 1.313 15h13.156c.98 0 1.902-1.16 1.219-2.344L9.375 1.125C8.977.48 8.434.121 7.906.094M9 4v5c.008.527-.473 1-1 1s-1.008-.473-1-1V4zm-1 7c.55 0 1 .45 1 1s-.45 1-1 1-1-.45-1-1 .45-1 1-1m0 0"/></svg> Disclaimer </strong><p>WORK IN PROGRESS!!! (while it does work finetuning still needs to be done and the code needs to be re-structured in some ways partially because I learned some new things about apl while writing this)</div><img src="https://github.com/bolives-hax/apl-raymarcher/blob/master/preview_final.png?raw=true"><h1 id=code>code</h1><h2 id=source-code>source code</h2><p>As for now I only provide build expression trough nix which are found alongside the source-code in <a href=https://github.com/bolives-hax/apl-raymarcher>this github repository</a>.<h2 id=running-it-yourself>running it yourself</h2><p>(see blogpost linked above for now) TODO …<h1 id=implementation-details>implementation details</h1><h2 id=so-how-does-it-work>so how does it work?</h2><p>With ray marching works pretty similar to ray tracing, but instead of checking if our ray intersects with object’s exposed surface through the means of algorithms such as <a href=https://en.wikipedia.org/wiki/M%C3%B6ller%E2%80%93Trumbore_intersection_algorithm>the Möller–Trumbore intersection algorithm</a>. We instead use something called <a href=https://en.wikipedia.org/wiki/Signed_distance_function>signed distance functions</a> or short “SDF” ’s. Essentially signed distance functions/SDFs are functions taking a given point in space <code>p</code> as their input parameter returning the distance from the given point <code>p</code> and the geometry it defines.<p>For example the SDF for a sphere would look something like this (in GLSL)<pre class="language-glsl z-code" data-lang=glsl><code class=language-glsl data-lang=glsl><span class="z-source z-glsl">flaot <span class="z-meta z-function z-glsl"><span class="z-entity z-name z-function z-glsl">sphereSDF</span></span><span class="z-meta z-function z-parameters z-glsl"><span class="z-meta z-group z-glsl"><span class="z-punctuation z-section z-group z-begin z-glsl">(</span></span></span><span class="z-meta z-function z-parameters z-glsl"><span class="z-meta z-group z-glsl"><span class="z-storage z-type z-glsl">vec3</span> <span class="z-variable z-parameter z-glsl">p</span><span class="z-punctuation z-separator z-glsl">,</span> <span class="z-storage z-type z-glsl">float</span> <span class="z-variable z-parameter z-glsl">radius</span><span class="z-punctuation z-section z-group z-end z-glsl">)</span></span></span><span class="z-meta z-function z-glsl"> </span><span class="z-meta z-function z-glsl"><span class="z-meta z-block z-glsl"><span class="z-punctuation z-section z-block z-begin z-glsl">{</span></span></span><span class="z-meta z-function z-glsl"><span class="z-meta z-block z-glsl">
</span></span></span><span class="z-source z-glsl"><span class="z-meta z-function z-glsl"><span class="z-meta z-block z-glsl">    # <span class="z-meta z-function-call z-glsl"><span class="z-support z-function z-glsl">length</span><span class="z-meta z-group z-glsl"><span class="z-punctuation z-section z-group z-begin z-glsl">(</span></span></span><span class="z-meta z-function-call z-glsl"></span><span class="z-meta z-function-call z-glsl"><span class="z-meta z-group z-glsl"><span class="z-punctuation z-section z-group z-end z-glsl">)</span></span></span> gets the length of its arguments vector
</span></span></span><span class="z-source z-glsl"><span class="z-meta z-function z-glsl"><span class="z-meta z-block z-glsl">    <span class="z-meta z-function-call z-glsl"><span class="z-support z-function z-glsl">length</span><span class="z-meta z-group z-glsl"><span class="z-punctuation z-section z-group z-begin z-glsl">(</span></span></span><span class="z-meta z-function-call z-glsl"><span class="z-meta z-group z-glsl">p</span></span><span class="z-meta z-function-call z-glsl"><span class="z-meta z-group z-glsl"><span class="z-punctuation z-section z-group z-end z-glsl">)</span></span></span> <span class="z-keyword z-operator z-arithmetic z-glsl">-</span> radius<span class="z-punctuation z-terminator z-glsl">;</span>
</span></span></span><span class="z-source z-glsl"><span class="z-meta z-function z-glsl"><span class="z-meta z-block z-glsl"></span></span><span class="z-meta z-function z-glsl"><span class="z-meta z-block z-glsl"><span class="z-punctuation z-section z-block z-end z-glsl">}</span></span></span>
</span></code></pre><p>Essentially taking the length of a point spanned from one point to another. As in some point along the ray originating from our camera subtracted by the radius of a sphere. Tells us how far away that sphere (with the given radius) is from the supplied point (passed as <em><strong>vec3 p</strong></em> in this example).</p><img src=https://ch-st.de/assets/posts/its-ray-marching-march/spheresdf.svg><p>A possible implementation of said SDF in APL may look like this: (Taken from my implementation):<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">ball_sdf←{  (length ⍵) - ⍺ }
</span></code></pre><p>with the <code>length</code> function being supplied trough:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">⍝ ⍺ =2 would mean the squareroot
</span><span class="z-text z-plain">sqrt←{⍵*÷⍺}
</span><span class="z-text z-plain">length←{2 sqrt (+/{⍵*2}¨⍵)}
</span></code></pre><p>Ok but how do we go from having a SDF to actually approximating where and if object is hit=visible?<p>Luckily that is quite simple to do. First we need to define some variables though<p><em>Assuming the function res supplies the horizontal and vertical resolutions as</em> <strong>(x y)</strong><pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">res←↑(get_res drawer ( 0 0 ))[2]
</span><span class="z-text z-plain">xres←(res)[1] ⋄ yres←(res)[2] 
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">cam_origin←(0 0 ¯1)
</span></code></pre><p>As we now have the dimensions of image/frame we intend to render. We map each pixel onto a 2 dimensional plane to to then cast ray trough each respectively mapped pixel coordinate <code>(x,y)</code>. There are various ways to represent our pixel/plane-coordinate mapping. In my approach I first span a map going from <strong><code>(0,0)</code></strong> to <strong><code>(1,1)</code></strong> and offset that to <strong><code>(-0.5,-0.5)</code> to <code>(0.5) (0.5)</code></strong> as I prefer that notation.<p>One way of implementing this would be trough<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">xy←{((⍳(xres))-1)⍵}¨((⍳(yres))-1)
</span><span class="z-text z-plain">_uv←{(⊃⍵[1]÷xres) (⍵[2]÷yres)}¨xy
</span><span class="z-text z-plain">uv←_uv-0.5
</span></code></pre><p>This illustration further outlines the process underwent</p><img src=https://varun.ca/static/ray-march-41bd80ce90cdf1dde6084381abf07d6f.svg><p>Before we can then run our SDF’s against the rays cast trough the 2d pixel/plane-coordinate mapping one should also apply the so called <a href=https://en.wikipedia.org/wiki/Aspect_ratio_(image)>aspect ratio</a> trough:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">uv←{⊃((⍵[1] ÷ (xres ÷ yres)) ⍵[2])}¨uv
</span><span class="z-text z-plain">uv_vecs ← ⊃,/{y←⍵[2] ⋄ {⍵ (-y)}¨(⊃⍵[1]) }¨uv
</span><span class="z-text z-plain">
</span></code></pre><p>With the pixel/plane-coordinate mapping in place and the aspect ratio being corrected. Generating rays is as simple as:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">{
</span><span class="z-text z-plain">	x←⍵[1]
</span><span class="z-text z-plain">	y←⍵[2]
</span><span class="z-text z-plain">	cam_dir←norm x y 1
</span><span class="z-text z-plain">    rgb cam_dir t 
</span><span class="z-text z-plain">}¨uv_vecs
</span></code></pre><p>The code above would emit an array of normalized directional vectors with the respective <code>(x y)</code> pixel/plane-coordinate mapping being apply the the vectors <code>x</code> and <code>y</code> directional components. This along with the camera origin would provide the basis for our camera model.<p>In my renderer the function <strong>rgba</strong> lays the basis to converting ray vectors to actual color values.<p>Now casting the ray is done using the abstract below<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">rgb cam_dir t 
</span></code></pre><p>where <code>cam_dir</code> is the vector with the directional components described above and <code>t</code> denoting time <em>(while not implemented yet one could reference the <code>t</code> variable if one wanted to render an animated scene)</em>.<p>Though you may ask yourself: why is it called ray marching? Like where is the actual <em>“marching”</em> taking place? And why do we even need to march in the first place? Isn’t using that SDF by itself enough?<p>Well essentially what would happen if you had lets say 2+ objects and the ray would come quite close to one object initially but then still pass by. Not actually intersecting the objects surface and maybe hit another object. As the SDF would still return the distance of the closest object (See below)</p><img src=https://www.tylerbovenzi.com/RayMarch/Assets/figure3.png><p>(TODO add a better ilustration)<p>this wouldn’t tell us too much. The SDF by itself doesn’t respect the rays direction but just provides a mere distance estimate. As you can see the distance it determines can represented in a fashion resembling the radius of a sphere. Meaning it only tells us the distance from one point to another point but not if it actually lays along a ray.<p>In order to accommodate for this issue. We essentially to approach the point we plan intersect in a step-wise manner. The smaller the lowest possible distance grows, the smaller further steps undertaken would be. If the distance is approaching 0 <em>(getting very close to it)</em> . We’d register that as a hit. Otherwise we would step on until either the max step count is reached or the maximum distance is exceeded.<p>The marching function is called from the <code>rbg</code> function described above, at the time of writing this it looks like this:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">⍝ ⍵ = [ cam_dir time bg ]
</span><span class="z-text z-plain">rgb←{
</span><span class="z-text z-plain">    cam_dir←⊃⍵[1]
</span><span class="z-text z-plain">	time←⊃⍵[2]
</span><span class="z-text z-plain">	d←(( 0 cam_origin  cam_dir 35 100) march 0)
</span><span class="z-text z-plain">	hit←d[1]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ 	phong ( total_dist , ro , rd , obj)
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	hit: phong ((d[2]) cam_origin cam_dir (d[3]))  
</span><span class="z-text z-plain">	⍝ not hit (render background)
</span><span class="z-text z-plain">	(sky cam_dir[1] (0 ⌈ ((cam_dir[2])+0.12)))
</span><span class="z-text z-plain">}
</span></code></pre><p>Essentially <code>d←(( 0 cam_origin  cam_dir 35) march 0)</code> is where the magic happens. Our march function will march along <code>cam_dir</code> vector, starting from <code>cam_origin</code>. The <code>35</code> denotes the maximum of <code>35</code> steps which will be taken. Of course that can be adjusted. For example rendering reflections should get away using a lower maximum step count, as less precision is needed there I figured. <code>100</code> denotes the maximum distance objects can have from the ray origin <em>(camera)</em> . So we render objects up until the vector length of <code>100.0</code> from the camera. While technically not needed, if we omitted this wed always take <code>35</code> or whatever out max step count is set to until giving up. This reduces the amount of unnecessary computations needed. The first argument of <code>march</code> is the distance stepped so far. We initialize this with 0, as march internally calls itself in a self referencing fashion with the distance value increasing when its supplied as the first parameter in further self referencing calls to <code>march</code>. The argument on the right most side of march is the <code>stepcount</code>. We also initialize this with 0 as march will every time it calls itself increment that by one.<p><code>march</code> first return value returns either <code>0</code> or <code>1</code> as in <code>(hit,...)</code> which is inspected before accessing the further return values, such as the distance <code>d[2]</code> or the respective id of the object hit <code>d[3]</code>. Further processing of <code>march</code>’s return values is bound to that first <code>hit</code> value. Since if march never hit anything, we couldn’t return anything in these fields and thus it would be pointless to work with them.<p>Assuming <code>hit=1</code> as in <strong>true</strong> wed call the <code>phong</code> function which would apply <a href=https://en.wikipedia.org/wiki/Phong_shading>the phong shading model</a> taking as its last parameter the id of the object hit. As knowing that we can from within <code>phong</code> apply different “material” properties by using different light absorption/reflection attributes in accordance with the <em>phong shading model</em>.<p>If nothing was hit the <code>sky</code> function will be called returning the <strong>r g b</strong> components of the background for the given point.<p>Now lets dissect the march function to gain a better understanding of it:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">⍝ ⍺ = [ total_dist , ro , rd , max_steps, max_dist ]
</span><span class="z-text z-plain">⍝ ⍵ = stepcount
</span><span class="z-text z-plain">march←{
</span><span class="z-text z-plain">	total_dist ← ⍺[1]
</span><span class="z-text z-plain">	ro ← ⊃⍺[2] 
</span><span class="z-text z-plain">	rd ← ⊃⍺[3]
</span><span class="z-text z-plain">	max_steps ← ⊃⍺[4]
</span><span class="z-text z-plain">	max_dist ← ⊃⍺[5]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	r ← sdf ( ro + rd × total_dist )
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	dist ← r[1]
</span><span class="z-text z-plain">	obj  ← r[2]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ if we exceeded the maximum amount of steps return 0
</span><span class="z-text z-plain">	⍝ AND we exceeded the maximum distance from the ray origin=( eg cam pos/point of reflection) return 0
</span><span class="z-text z-plain">	
</span><span class="z-text z-plain">	⍝ TODO use dist to simulate fog  by adding some fog color value based on the distance
</span><span class="z-text z-plain">	⍵&LTmax_steps ^ dist < max_dist: {
</span><span class="z-text z-plain">		dist < epsi: (1 (dist + total_dist) obj )
</span><span class="z-text z-plain">		( (dist + total_dist) ro rd max_steps max_dist) march ⍵
</span><span class="z-text z-plain">	} ⍵+1
</span><span class="z-text z-plain">	(0 0)
</span><span class="z-text z-plain">}
</span></code></pre><p>I believe the abstract is pretty self explanatory but in essence <code>r ← sdf ( ro + rd × total_dist )</code> is of most interest. All <em>SDF’s</em> at least take one parameter <code>p</code> which denotes the point in space the signed distance function returns the respective <em>distance</em> to. In order to <em>“march”</em> we must progress our directional vector <code>rd</code> derived trough the pixel mapping above by the <code>total_dist</code> factor to get the current distance to run our intersection-range checks against. This needs to be added to the camera origin positional vector <code>ro</code>. We could also leave <code>ro</code> out but then our camera would be restricted to being located at <code>0 0 0</code>. But to deliver more flexibility here and as the march function is used in other places within this program <em>(for example for marching along reflection rays which start from the surface we reflected from)</em> . So its generally better to add <code>ro</code> here.<p>We could for example set <code>r</code> to the <code>ball_sdf←{  (length ⍵) - ⍺ }</code> function as showcased early on in this article. <code>⍵</code> denotes the point <code>p</code> in this case <code>ro + rd × total_dist</code> while <code>⍺</code> represents the radius of the sphere. Were not limited to a single sphere sdf. Of course one could also combine multiple sdf’s trough use of the <code>⌊</code> > <strong>minimum</strong> operator.<p>For example showing 2 spheres. One in the center of our scene and one located at <code>y=+1</code> trough defining/calling:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">(ball_sdf (p - (0 0 0)) ⌊ (ball_sdf (p - (0 1 0))
</span></code></pre><p>This works as it would return the distance to the sphere closest to us. <code>(-sdf1) ⌈ (sdf2)</code> could be used to carve out the first geometry defined by the first sdf from the second one <strong>NOTE: this “-” sign is required here</strong>. Likewise using <code> (sdf1) ⌈ (sdf2)</code> <strong>max</strong> would instead return only the points where <code>sdf1</code> intersects with <code>sdf2</code>. There are lots of tricks that can be used when working with signed distance functions. But it should already be clear that even with just min and max and + and - one can compose some pretty complex geometry.<p>Now I will focus on the call to the <code>phong</code> function seen before in <code>rgb</code>. <code>rgb</code> has the section:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">hit: phong ((d[2]) cam_origin cam_dir (d[3]))  
</span></code></pre><p>which essentially runs <code>phong</code> with the parameters<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">⍝ ⍵ = [ total_dist , ro , rd , obj]
</span></code></pre><p>The start of <code>phong</code> is structured like this:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">
</span><span class="z-text z-plain">⍝ ⍵ = [ total_dist , ro , rd , obj]
</span><span class="z-text z-plain">phong←{
</span><span class="z-text z-plain">	total_dist←⊃⍵[1]
</span><span class="z-text z-plain">	ro←⊃⍵[2]
</span><span class="z-text z-plain">	rd←⊃⍵[3]
</span><span class="z-text z-plain">	obj←⍵[4]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	p←ro + rd × total_dist
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	
</span><span class="z-text z-plain">	l1←{
</span><span class="z-text z-plain">		ambient_color←checkers_ball p
</span><span class="z-text z-plain">		diffuse_color←0.5 0.5 0.5
</span><span class="z-text z-plain">		specular_color←0.1 0.1 0.1
</span><span class="z-text z-plain">		alpha←0.7
</span><span class="z-text z-plain">		light_intensity←⍵
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">		ambient_color diffuse_color specular_color alpha light_intensity 
</span><span class="z-text z-plain">	} 0.5
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    ⍝ ... further lights
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	lightPos←3 3 0 ⍝ hardcoded here but could ofc be passed  via ⍵[5]
</span><span class="z-text z-plain">
</span></code></pre><p><code>l1</code> defines a light locally. In my case <code>phong</code> defines <code>l1</code> - <code>l7</code>.<p>Instead of trying myself at explaining what<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">ambient_color←checkers_ball p
</span><span class="z-text z-plain">diffuse_color←0.5 0.5 0.5
</span><span class="z-text z-plain">specular_color←0.1 0.1 0.1
</span></code></pre><p>does. I will just include a picture that gets the point across</p><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Phong_components_version_4.png/800px-Phong_components_version_4.png><p>following <code>lightPos</code> seen above comes<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">⍝ checkered ball
</span><span class="z-text z-plain">⍵=scene_obj1_ball: l1 phongLight p ro
</span><span class="z-text z-plain">⍝ octahedron
</span><span class="z-text z-plain">⍵=scene_obj2_octa: l2 phongLight p ro
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">⍝ blob
</span><span class="z-text z-plain">⍵=scene_obj3_melted_balls: l3 phongLight p ro
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">⍝ floor
</span><span class="z-text z-plain">⍵=scene_obj4_floor: (l4 phongLight p ro) + (4 checkers ((p[1]) (p[3])))
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">⍵=scene_obj5_frame: (l5 phongLight p ro)
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">⍵=scene_obj6_ball: (l6 phongLight p ro) + ( 0.5 × (0.11 checkers ((p[1]) (p[2]))))
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">⍵=scene_obj7_torus: (l6 phongLight p ro) + ( 0.5 × (0.22 checkers ((p[1]) (p[2]))))
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">⍵=scene_obj8_rounded_box: reflective_material ( p rd ro scene_obj8_rounded_box l7)
</span></code></pre><p>assuming of course the <code>scene_objX_NAME</code>-type variables are defined somewhere accessible. In my case globally like shown below. Note that there is no catchall/default expression. I intentionally chose this so I don’t accidentally forget handling each defined object individually. But you could of course just write something like:<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">    ⍵=scene_objX_NAME: (l_X phongLight p ro)
</span><span class="z-text z-plain">    (l_default phongLight p ro)
</span></code></pre><p>With <code>(l_default phongLight p ro)</code> being applied for any unmatched object. <code>phongLight</code> takes the as its left-side parameter whats defined above by <code>l1</code>-<code>l7</code> and as the parameters on the right <code>p</code> and <code>ro</code>. <code>ro</code> in this case provides the position of the camera and <code>p</code> being the point on a surface <code>march</code> detected an intersection with. Based on that information, <code>phongLight</code> returns a color in the <code>(r g b)</code> <strong>(float float float)</strong> specification. Please note that as <code>⍵=scene_obj8_rounded_box</code> is a little special special I will document it later on. As its the only object with reflective properties in the scene.<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">scene_obj1_ball←1 
</span><span class="z-text z-plain">scene_obj2_octa←2
</span><span class="z-text z-plain">scene_obj3_melted_balls←3
</span><span class="z-text z-plain">scene_obj4_floor←4
</span><span class="z-text z-plain">scene_obj5_frame←5
</span><span class="z-text z-plain">scene_obj6_ball←6
</span><span class="z-text z-plain">scene_obj7_torus←7
</span><span class="z-text z-plain">scene_obj8_rounded_box←8
</span></code></pre><p>Knowing the object id in <code>⍵</code> is quite useful here, as it allows us to apply <strong>phong shading</strong> or even textures/reflection properties on various objects individually. If we were to omit it, wed either have to calculate it again by throwing <code>p</code> back into in the sdf’s again or we would have to assign the same texture and <strong>phong shading</strong> properties to every object.<p>So now lets look at <code>phongLight</code>:<p>The picture below should provide some hints of what is going on in there</p><img src=https://blog.kakaocdn.net/dn/ct4wDp/btrB5880JNi/3goJCO3Sy0tqmiTLemvUC0/img.png><pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">⍝ ⍺ = [ ambient_color(rgb), diffuse_color(rgb), specular_color(rgb), alpha, light_intensity ]
</span><span class="z-text z-plain">⍝ ⍵ = [ p ro ]
</span><span class="z-text z-plain">phongLight←{
</span><span class="z-text z-plain">	p←⊃⍵[1]
</span><span class="z-text z-plain">	ro←⊃⍵[2]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ TODO REMOVE 0.5 (DEBUG)
</span><span class="z-text z-plain">	ambient_color←(⊃⍺[1]) × 0.5
</span><span class="z-text z-plain">	diffuse_factor←⊃⍺[2]
</span><span class="z-text z-plain">	specular_factor←⊃⍺[3]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	alpha←⊃⍺[4]
</span><span class="z-text z-plain">	light_intensity←⊃⍺[5]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ estimate the normal vector at point p on the surface
</span><span class="z-text z-plain">	n ← estNormal p
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ light position ( TODO don't hardcode up here ) 
</span><span class="z-text z-plain">	light_pos←((0) (3) (1))
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ vector between the point on the surface and the light position
</span><span class="z-text z-plain">	l← norm ( light_pos - p)
</span><span class="z-text z-plain">	⍝ vector between the point on the surface and the view/camera/etc vector
</span><span class="z-text z-plain">	v← norm ( ro - p)
</span><span class="z-text z-plain">	⍝ vector  reflecting the light-surface vector on the estimated surfaces normal vector 
</span><span class="z-text z-plain">	r← norm ( (-l) reflect n )
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ dot product of both
</span><span class="z-text z-plain">	dotln ← l dot n
</span><span class="z-text z-plain">	dotrv ← r dot v
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ the light doesn't hit the surface at any relevant angle
</span><span class="z-text z-plain">	dotln < 0.0: 3 ⍴ 0.0
</span><span class="z-text z-plain">	
</span><span class="z-text z-plain">	c ← ambient_color + {
</span><span class="z-text z-plain">		⍝ angle not in range for specular effect, just apply diffuse color
</span><span class="z-text z-plain">		⍵ < 0.0: diffuse_factor × dotln
</span><span class="z-text z-plain">		⍝ angle in range for specular effect, apply diffuse and specular colors
</span><span class="z-text z-plain">		diffuse_factor × dotln + specular_factor × ( dotrv × alpha )  
</span><span class="z-text z-plain">	} dotrv 
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	light_intensity × c
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">}
</span><span class="z-text z-plain">
</span></code></pre><p>Essentially based on what angle we look at the surface from and the position of a light we can determine if a <strong>specular</strong> effect should be present or rather just the diffuse lighting effect alone. Or if the light sources rays never even hit the object in the first place. Based on if any of the 3 cases <em>(not hit, hit diffuse, hit specular)</em> we apply these effects<p>Now to <code>scene_obj8_rounded_box:</code> which is special in the sense that it doesn’t just apply <strong>phong shading</strong> but also simulates a reflective surface.<p>What essentially happens here is that if <code>obj=scene_obj8_rounded_box: reflective_material</code>, meaning the rounded box “8” got hit by a ray cast from the camera. Instead of applying <strong>phong shading</strong> like we do with the other objects. Whats being done here is that similar to how its done when applying <strong>phong shading</strong>. We take into account from what angle were looking at the object from. Using the estimated normal vector of the point on the surface the camera ray is pointing at and the view angle we can reflect the ray accordingly.</p><img src=https://media.geeksforgeeks.org/wp-content/uploads/20220915162140/WhatisReflectionofLight.png><p>So knowing what the vector/ray direction after being reflected allows us to do the following: We essentially do the same as what we did when casting rays from the camera upon non reflective objects. But instead of the ray origin being the camera and the ray direction being determined trough which pixel on our plane it goes, the ray origin is the position our ray originating from the camera hit the reflective surface at. Likewise we use the reflected directional vector as our new directional vector.<p>One could think of it roughly as us <del>moving the camera to the point were reflecting from</del> . using this new information we then undergo the marching loop once again by calling the <code>march</code> function. Note that the maximum step count was reduced to 20 and the maximum distance to 40 as reflections generally need less accuracy.<p><strong>IMPORTANT DETAIL:</strong> note the line specifying <code>ref_surface_p ← ref_surface_p + ref_surface_n × 0.005</code> makes up a <strong>VERY!!</strong> very important detail. Basically what happens here is that we shift the origin we use when casting the reflected ray by a tiny bit forward <em>(towards the normal vector of the surface)</em> to avoid it intersecting with itself.<p>Whats left is performing <strong>phong shading</strong> on the object initially hit not the reflection. To then combine that with the color values returned after performing the reflection. As otherwise wed have a perfect mirror though (you likely couldn’t tell its a mirror). So in order to be able to tell it apart as a reflective surface it can’t perfectly reflect everything and needs to perform some sort of modification to the colors it reflects. As for now <code>l7</code> gives it a slightly yellow tint.<p>The line doing that job is essentially <code>col_obj_self← (light phongLight ref_surface_p  ro )×0.3</code> and at the return segment<pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">	hit: ((t ref_reflected_final)×0.7) + col_obj_self
</span><span class="z-text z-plain">        	⍝ nothing hit, thus apply background accoring to the reflected vectors orientation
</span><span class="z-text z-plain">        	((sky (ref_reflected_rd[1])  (0 ⌈((ref_reflected_rd[2])+0.12)))×0.5) + col_obj_self
</span></code></pre><pre class="language-apl z-code" data-lang=apl><code class=language-apl data-lang=apl><span class="z-text z-plain">reflective_material←{
</span><span class="z-text z-plain">	ref_surface_p ← (⊃⍵[1])
</span><span class="z-text z-plain">	ref_view_rd ← (⊃⍵[2])
</span><span class="z-text z-plain">	ro ← (⊃⍵[3])
</span><span class="z-text z-plain">	obj_self← (⊃⍵[4])
</span><span class="z-text z-plain">	light ← (⊃⍵[5])
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    	⍝ normal vector of the point we hit the surface at
</span><span class="z-text z-plain">	ref_surface_n ← estNormal ref_surface_p
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    	⍝ IMPORTANT !!! V
</span><span class="z-text z-plain">    	⍝ slightly offset the origin to cast the reflected ray from in the direction of the reflecting surfaces
</span><span class="z-text z-plain">    	⍝ normal vector (which will always point away from it)
</span><span class="z-text z-plain">	ref_surface_p ← ref_surface_p + ref_surface_n × 0.005
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    	⍝ reflect the camera to reflective surface vector using the surfaces normal vector at that position
</span><span class="z-text z-plain">	ref_reflected_rd ← norm (    ref_view_rd reflect ref_surface_n )
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    	⍝ initiate raymarching once more but this time starting from the reflecting surface
</span><span class="z-text z-plain">    	⍝ using a slightly reduced  step count/max distance
</span><span class="z-text z-plain">	ref_reflected_final  ← ( 0 ref_surface_p ref_reflected_rd 70 150) march 0
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">	⍝ 1 if the reflected ray hit anything, otherwise 0 
</span><span class="z-text z-plain">	hit←(ref_reflected_final[1])
</span><span class="z-text z-plain">	t←{
</span><span class="z-text z-plain">		dist←⍵[2]
</span><span class="z-text z-plain">		obj_is_self← (⍵[3])=obj_self
</span><span class="z-text z-plain">        	⍝ object intersected with itself ( should never happen for now just color it in a vibrant
</span><span class="z-text z-plain">        	⍝ green soits easy to debug or maybe throw an exception 
</span><span class="z-text z-plain">		obj_is_self: ( 0 1 0) 
</span><span class="z-text z-plain">            		⍝object didn't intersect with itself, apply phong shading at the point the reflection ray hit at
</span><span class="z-text z-plain">            		phong (dist ref_surface_p ref_reflected_rd (⍵[3]))
</span><span class="z-text z-plain">	}
</span><span class="z-text z-plain">	col_obj_self← (light phongLight ref_surface_p  ro )×0.3
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    	⍝                      V phong shading at the point the reflection hit at 
</span><span class="z-text z-plain">	hit: ((t ref_reflected_final)×0.7) + col_obj_self
</span><span class="z-text z-plain">        	⍝ nothing hit, thus apply background accoring to the reflected vectors orientation
</span><span class="z-text z-plain">        	((sky (ref_reflected_rd[1])  (0 ⌈((ref_reflected_rd[2])+0.12)))×0.5) + col_obj_self
</span><span class="z-text z-plain">	⍝ TODO ^ instead of using these hardcoded values allow the user to specify the factor of what
</span><span class="z-text z-plain">	⍝ rgb components get reflected more and make it bound to distance. For now this is too
</span><span class="z-text z-plain">	⍝ enhance obj reflecitons while not reflecting the background too much but thats ofc just a hack
</span><span class="z-text z-plain">}
</span></code></pre><p class=dialog-buttons><a class=inline-button href=#top>Go to Top</a> <a class="inline-button colored" href>File an Issue</a></div><footer id=site-footer></footer>